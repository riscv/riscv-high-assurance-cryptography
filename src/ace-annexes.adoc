== Annexes

[[ACE-CSK-vs-ID]]
=== Programmable CSKs vs. ID-based Usage Control vs. Localities

_This section is informative and non-normative._

ACE provides a layer of usage control based on the use of Localities.

- One option is to add an optional Metadata Extension block that contains values of `scontext` and `mcontext` (from Sdtrig) to match against, or alternative values based on ad hoc CSRs.
+
This is a lightweight mechanism.
Since filtering at one mode is inactive when the hart is in a higher mode, context switching can be performed without modifying the CSK.

. A programmable CSK can restrict not only the usage, but even the import of CCs.
This offers stronger security by also preventing unauthorized `ace.import` operations, but incurs higher overhead as it typically requires an `ecall` to modify the CSK, and
increases pressure on the ACE unit's internal resources in case keys derived from the most recent CSK values are cached.

. Localities programmable at M/H/S could be used instead.
Since these Localities can be combined with the HW Binding localities, this would be as flexible as context-based filtering, but based on significantly longer strings.

The envisioned usage model employs context-based filtering at the User level, and also at the (Virtual) Supervisor level in high-performance systems where migration is not required (e.g., automotive applications).
Cryptographic domain separation via the CSK or Localities is intended for Virtual Machines, Supervisor Domains, Worlds, and TEEs, as these demand stronger security guarantees.

Although the architecture does not prevent assigning unique CSKs to U-mode processes, doing so would impose a substantial burden on system software due to per-context-switch `ecall` overhead.
Hardware support—such as automatic CSK switching based on contexts could alleviate this burden.
Such a mechanism is not under consideration due to its architectural complexity, inflexibility, and hardware cost.
For example, it would necessitate secure management of large CSK tables, including saving, restoring, and potentially migrating entire CSK blocks.

// ///////////////////////////////////////////////////////////////////////////////////////////

[[ACE-lazy-loading]]
=== Lazy-Loading CRs

_This section is informative and non-normative._

[WARNING]
Architecting this feature requires careful consideration—there may be further corner cases, so both architectural states and expected software behavior need to be analyzed in depth. Focusing on the core features of ACE is more important and designing lazy-loading is a secondary concern.

Lazy loading defers loading a value until it is needed, improving performance and managing limited CRF capacity. It may also be required to support migration to systems with smaller CRFs:
If capacity is insufficient for lazy loading, the software reimporting an offloaded CR must be able to offload other CRs to free space. Requiring software to check for errors after each operation would impose significant burden on the software and possibly degrade performance.

Assume that, besides `scrdirty`, `vscrdirty` and `mcrdirty`, three more CSRs `scrlazy`, `vscrlazy` and `mcrlazy` are defined to mark a CR as lazy, i.e., CR number __i__ is *LAZY* if ```\*crlazy```[__i__] is set and ```*crdirty```[__i__] is not set.
// Alternatively, we can define *crdirty to be a 64 bit register and reserve
// the upper 32 bits for lazy.
// We can define the crdirty to be a two bit per CR, just split over two
// 32 bit blocks, a two bit per-CR field would be 32+X and X.
// There might be even a slight case to make the upper 32 bits read-only-1 now, so we
// could pretend to encode the Clean (0b10) and Dirty (0b11) consistently with
// the previous format.
A CR marked *LAZY* is Unconfigured. An authoritative value is saved for lazy loading in one of the parent modes.
Unconfiguration and configuration operations on this CR work normally.
// This allows lazy loads, but lazy stores are also potentially useful.
// If we don't expect a context to use the CR, we could just keep the value
// of another context there, which would allow us to preserve the CR for the
// original context and avoid both save and load.
// More traps would even allow for more evil optimizations, like giving just 8
// CRs to a context, and keeping up to 4 contexts in the file, provided parent
// mode also gets traps when there isn't enough memory to import.

If an *Export* or *Usage* operation is issued at U-mode, then the system traps to the higher-privileged mode that holds the authoritative SCC, which must import it into the CR.
This may require freeing space by making another CR *LAZY*.

Identifying the correct higher-privileged mode is typically straightforward.
There is however one complex case, which occurs when:

  . U‑mode is preempted by the hypervisor (HV).
  . HV saved the CR, cleared it and then marked it *LAZY* to be loaded on demand later.
  . If the CR was *CLEAN*, an SCC in VS-mode would be authoritative, and if there were no SCC in VS-mode, the value in HS would be authoritative, so retrieving the value from the parent first, and grandparent otherwise, works well.
  . _However, if the CR was *DIRTY*, the authoritative value resides in HS, while VS‑mode may hold a stale copy_.
  Therefore, the prior dirtiness information must be consulted to retrieve the authoritative SCC from HS rather than from S‑mode.
  This is addressed by using the fourth possible CR status, which is encoded as ``*crlazy``[__i__] = ``*crdirty``[__i__] = 1, which we call **LAZY/DIRTY**:
  When S receives the request to restore the CR, it must relay it to HS, and both VM and hypervisor must support the feature.

 . After the import, the CR is set to *CLEAN* and the interrupted operation is restarted.

This is a corner case and it would _not_ happen in the most common situation, namely:

*** The OS at VS-mode may implement lazy loading.
*** Hypervisors and M _always_ save _and_ restore the _entire_ state.
*** We do not migrate a VM if the CRF capacity at the destination machine is insufficient (the only case that would actually force the hypervisor to not restore everything but making at least some CRs lazy).

Furthermore, one can envision a more complex situation where U-mode is interrupted by M-mode and _both_ the OS and the HV contain stale copies.
This situation is resolved in this case by having M always saving and restoring the entire state, whereas only at HS and VS CRs can be made LAZY.

// ///////////////////////////////////////////////////////////////////////////////////////////

[[ACE-architectural-model]]
=== Architectural Model

ACE is architected as an _attached_ unit.
This allows implementations both within each core and as a block shared by multiple cores, with a single instance of the hardware and one separate architectural state for each hart.
The present specification mandates only its behavior, not its implementation.

Consequently, ACE instructions behave as messages over a tightly coupled coprocessor interface.
The ACE unit accepts operations, executes them independently of the issuing hart, and later returns results.
To enforce this decoupling, the ACE unit may lock certain architectural states, for instance Context Registers and CSRs, causing the hart to wait when attempting to read them.

This design permits a certain degree of concurrency: ACE operations may proceed even while the control flow of the hart is preempted, and long-running cryptographic computations are allowed. Certain interrupts, however, may be permitted to suspend ACE operations.

For example, let us consider a U‑mode process executing an ACE instruction that modifies only internal state, say, a vector register.
If the process is preempted, the ACE unit may continue its work until the context‑switch handler attempts to access that register, at which point the hart would wait for the operation to finish.
Alternatively, an implementation may adopt a more precise exception model: halting the ACE unit, setting `acestart` to allow later resumption. Optionally the implementation may impose a timeout before halting precisely.
The architecture permits all these approaches and fully specifies the behavior of ACE instructions when interrupted at admissible points.

// ///////////////////////////////////////////////////////////////////////////////////////////

[[ACE-threat-model]]
=== Threat Model

_This section is informative and non-normative._

The ACE threat model is straightforward.

**Assets** consist of _keys_ and any other information that could aid an adversary in recovering plaintext or forging ciphertext. This includes items such as masks in tweakable XEX modes and derived keys in AES-GCM-SIV. The critical properties of these assets are their _confidentiality_ and _integrity_.
Protecting the _Availability_ of the keys is not a goal of the architecture.

**Adversaries** are assumed capable of compromising processes by exploiting software vulnerabilities.
They are also able to gain access to memory contents, for instance, by abusing hardware interfaces or by SoC/memory interposition.
The model does not include adversaries capable of sophisticated hardware attacks, such as using
a Focused Ion Beam/Scanning Electron Microscope (FIB/SEM) to tamper with the hardware's functionality.

Side channel attacks are addressed optionally. ACE offers interfaces to both SCA-unprotected and SCA-protected implementations of cryptographic algorithms, if these options are provided by the designer.

Threats can be addressed in four ways:

[horizontal]
**C:**:: _Control_ the threat by implementing full or partial mitigations.
**A:**:: _Accept_ the threat and its associated risks.
**T:**:: _Transfer_ the threat to another party better suited to address it.
**S:**:: _Suppress_ the features that give rise to the threat.

ACE is designed to avoid the “*A*” and “*S*” options (as much as possible). It _controls_ threats through its own mechanisms and _transfers_ residual risk—specifically, the risk of key extraction from the privileged or trusted software and hardware environments that manage keys—to those same environments. For example, trusted software environments may employ control-flow integrity, memory encryption with integrity protection, and anti-replay mechanisms, while hardware key-management blocks can be hardened to protect entrusted keys.

Direct plaintext leakage, memory corruption attacks against the ACE-using process, and Release of Unverified Plaintext (RUP) attacks on the cryptographic algorithms are considered out of scope. These threats cannot be mitigated by ACE because the processed information resides within the user execution context. Consequently, these threats are _accepted_.

// ///////////////////////////////////////////////////////////////////////////////////////////
